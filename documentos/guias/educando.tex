En la sexta clase del curso, continuamos trabajando con algor\'itmos de clasificaci\'on
de im\'agenes, centrandonoces ne este caso en los no supervisados. Son nuestros objetivos:

\begin{itemize}
  \item Poder realizar clasificaciones no supervisadas utilizando los distintos
  algoritmos que se encuentran en R.
  \item Calcular la distancia espectral entre como forma de determinar la separabilidad
  de dos clases espectrales.
  \item Comparar utilizando la entropia de un pixel que coberturas presentan
  mayor confusion al momento de la clasificacion.
\end{itemize}

Cargaremos primero la imagen landsat 8 y habilitaremos la opcion para escribir
el header de ENVI\@. Usaremos en primer lugar los paquetes \texttt{raster},
\texttt{rgdal} y \texttt{RStoolbox}.

\begin{lstlisting}
    rasterOptions(addheader = "ENVI")
    xml.2016 <- readMeta("raster_data/LC82240782016304/LC82240782016304LGN00.xml")
    ref.2016 <- stackMeta(xml.2016, quantity = "sre")
    scaleF <- getMeta(ref.2016,xml.2016, what = "SCALE_FACTOR")
    ref.2016 <- ref.2016 * scaleF
    ref.2016 <- ref.2016[[-1,]]
    names(ref.2016) <- c("blue","green","red","nir","swir1","swir2")
    vector <- readOGR(dsn="vector_data/", layer="entrenamiento")
\end{lstlisting}

\subsection{Clasificador por m\'axima verosimilitud}

Empecemos con la clasificacion por el metodo de maxima verosimilitud, para esto
necesitamos del paquete

\begin{lstlisting}
    sup.2016 <- superClass(ref.2016, vector, responseCol = "MC_ID",
                           model = "mlc")
    plot(sup.2016, col=rainbow(8))
\end{lstlisting}

y realizar el scatterplot de dichas variables como.

\begin{lstlisting}
    ref.mlc <- stack(ref.2016,sup.2016$map)
    xyplot(nir~red, groups=MC_ID , data=ref.mlc)
\end{lstlisting}

Cambiando el algoritmo de clasificacion en el parametro \texttt{model} podemos
calcular distintas clasificaciones supervisadas. Algunas de las vistas en clase
son \texttt{rf}, \texttt{svmRadial}, \texttt{kNN}. Cada una de ellas usa alguna
libreria adicional de las cargadas antes.

\begin{exa}
  Una forma de mejorar las clasificaciones supervisadas basadas en el espacio
  espectral es clasificar por separado distintas clases espectrales y luego unirlas
  en la misma clase de informacion. Veams como hacerlo.
  \begin{lstlisting}
      sup.2016b <- superClass(ref.2016, vector, responseCol = "C_ID",
                             model = "mlc")
  \end{lstlisting}

  Una vez realizada la clasificacion, debemos substituir los valores de cada pixel
  por el de la clase de informacion correspondiente. Para ello hacemos

  \begin{lstlisting}
    subs.2016 = vector@data[c(3,1)]
    sub.2016 <- reclassify(sup.2016b$map, subs.2016)
    writeRaster(sub.2016, "raster_data/processed/mlc2016",
                datatype="INT1U")
    plot(sub.2016, col=rainbow(8))
  \end{lstlisting}


    Podemos finalmente comparar las dos imagenes clasificadas lado a lado ejecuntado el
    comando \verb|plot(stack(sup.2016$map,sub.2016),col=rainbow(8))|
\end{exa}

\begin{act}
    Realice clasificaciones por los distintos metodos y comparelas visualmente.
\end{act}

\begin{act}
    Agregue las bandas de textura y evolucion temporal del NDVI y vuelva a clasificar
    las imagenes.
\end{act}

\subsection{Entropia de la clasificacion}

Para poder comparar en que zonas los clasificadores presentan mas o menos
dispersion podemos calcular la entropia de las distintas clasificaciones en cada
pixel. Para esto utilizaremos la funcion \texttt{rasterEntropy}.

\begin{exa}
  Para esto comenzamos corriendo la clasificacion para distintos modelos, los apilados y
  despues calculamos la entropia de los mismos

  \begin{lstlisting}
      set.seed(42)
      sup.2016 <- superClass(ref.2016, vector, responseCol = "C_ID",
                           model = "mlc")
      mlc.2016 <- reclassify(sup.2016$map, subs.2016)

      library(randomForest)
      sup.2016 <- superClass(ref.2016, vector, responseCol = "C_ID",
                           model = "rf")
      rf.2016 <- reclassify(sup.2016$map, subs.2016)

      library(kernlab)
      sup.2016 <- superClass(ref.2016, vector, responseCol = "C_ID",
                           model = "svmLinear")
      svm.2016 <- reclassify(sup.2016$map, subs.2016)

      prediction_stack <- stack(mlc.2016, rf.2016, svm.2016)
      names(ensemble) <- c("mlc","rf","svm")

      model_entropy <- rasterEntropy(prediction_stack)
  \end{lstlisting}

  Podemos graficar la entropia de las clasificaciones como \verb|model_entropy|
  y ver que zonas presentan mas diferencias a la hora de la clasificacion y cuales no.
  \begin{lstlisting}
    plot(stack(prediction_stack, model_entropy),col=rainbow(8))
  \end{lstlisting}
\end{exa}

\begin{act}
  Repita las clasificaciones por los metodos de arriba agregando la banda
  textura y de variacion temporal del ndvi. Apilela junto con las clasificaciones por
  k-means de la clase anterior. Â¿A que cobertura pertenecen las zonas con mayor
  variabilidad?
\end{act}
